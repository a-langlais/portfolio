<!DOCTYPE html>
<html lang="fr">
    <!-- Header -->
    <head>
        <meta charset="utf-8">	
        <!-- Bootstrap v3 -->
        <link href="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css" rel="stylesheet">
        <!-- FontAwesome v6 -->
        <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
        <!-- Fonts -->
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Comfortaa|Open+Sans:400,300,700">
        <!-- Custom CSS styles -->
        <link rel="stylesheet" href="../assets/styles.css">
    </head>

<body class="home">
    <header id="header">
        <div id="head" class="parallax" parallax-speed="2">
            <h1 id="logo" class="text-center">
                <img class="img-circle" src="../images/profile-pic.png" alt="">
                <span class="title">Alexandre LANGLAIS</span>
                <span class="tagline">Analytics Data Scientist | AI & Statistics<br>
                    <a href="mailto:langlais.alexandre03@gmail.com">langlais.alexandre03@gmail.com</a></span>
            </h1>
        </div>
    </header>
    <!-- /Header -->

<main id="main">
	<div class="container">
		<div class="row topspace">

			<!-- Sidebar -->
			<aside class="col-md-4 sidebar sidebar-left">
                <!-- Keywords -->
				<div class="row widget">
					<div class="col-xs-12">
						<h4>Mots cl√©s</h4>
						<div class="keywords">
							<span class="tag">Python</span>
							<span class="tag">WebScraping</span>
                            <span class="tag">Transformers</span>
                            <span class="tag">LLM</span>
                            <span class="tag">Mailing</span>
						</div>
					</div>
				</div>
                <!-- /Keywords -->

                <!-- Links -->
				<div class="row widget">
					<div class="col-xs-12">
						<h4>Liens</h4>
						<p class="repo-icons">
							<a href="https://github.com/a-langlais/rss_summarizer">
								<i class="fab fa-github fa-2"></i> GitHub
							</a><br>
                            <a href="https://github.com/a-langlais/rss_summarizer/blob/main/README.md">
								<i class="fa-solid fa-book"></i> Documentation
							</a><br>
							</a>
						</p>
					</div>
				</div>
                <!-- /Links -->

			</aside>
			<!-- /Sidebar -->

			<!-- PageContent -->
			<article class="col-sm-8 maincontent">
				<header class="page-header">
					<h1 class="page-title">Veille informative automatique via scraping de flux RSS</h1>
				</header>
                <p>Se tenir informer est un enjeu crucial √† notre √©poque. Avec la multitude de sources d'information et la rapidit√© d'√©volution des technologies, il est facile de passer √† c√¥t√© d'une nouveaut√© importante. Chacun √† sa propre strat√©gie concernant la veille informative. Pour ma part, j'ai souhait√© automatis√© de mani√®re hebdomadaire la r√©cup√©ration des articles des diff√©rents sites ou r√©seaux sociaux que je suis activement, en compl√©ment de ma veille active au quotidien. On retrouve beaucoup de solutions √† base d'automatisation no-code ou low-code, mais je ne retrouvais pas la souplesse et la finesse que je recherche dans ce genre d'outil, c'est pourquoi j'ai voulu concevoir mon propre programme.</p>
				
                <h3>R√©cup√©ration des donn√©es</h3>
                <p>Dans un premier temps, le programme r√©cup√®re les derniers articles des diff√©rents flux RSS qui ont √©t√© saisis dans le fichier de configuration (il ne s'agit que d'une simple liste facile √† modifier sur la dur√©e). Le programme r√©cup√®re ainsi les derniers articles des 7 derniers jours. le titre de l'article, sa date de publication et son URL sont r√©cup√©r√©s par la m√™me occasion gr√¢ce au package <code>feedparser</code>.</p>
                <p>Pour que la veille soit efficace, il est souhaitable d'avoir un petit r√©sum√© court et journalistique associ√© √† l'article, afin de pouvoir savoir rapidement s'il sera int√©ressant ou non. Pour cela, le programme va scraper les articles √† partir de l'URL r√©cup√©r√©e pr√©c√©demment. Le scraping des articles est ainsi rendu possible gr√¢ce aux packages <code>requests</code> et <code>BeautifulSoup</code>.</p>

                <h3>R√©sum√© et reporting</h3>
                <p>Les donn√©es ainsi scrap√©es et agr√©g√©es des diff√©rents articles n√©cessitent alors une phase de nettoyage pour √™tre pleinement exploit√©es, notamment en retirant les diff√©rentes balises HTML non n√©cessaires issues du scraping. Suite √† cela, le programme utilise un mod√®le de langage open-source sp√©cialis√© dans les courts r√©sum√©s journalistiques (<code>facebook/bart-large-cnn</code>) disponible sur Hugging-Face via le package <code>transformers</code> (de plus, il fonctionne particuli√®rement bien pour les articles en fran√ßais comme en anglais). Ainsi, les donn√©es agr√©g√©es maintenant propres sont pass√©es au mod√®le qui va, pour chaque article, r√©aliser un court r√©sum√© d'environ 60-100 mots.</p>
                <p>Maintenant que tous les √©l√©ments sont propres et format√©s pour chaque article, les √©l√©ments sont mis en forme selon un mod√®le Markdown. Une fois chaque article trait√©, le document Markdown est export√© afin d'avoir une trace du contenu cr√©√© suite √† la veille informative.</p>
                <center>
                    <img src="../pages/images/rss_preview.png" alt="report_veille" width="80%">
                    <p class="caption">Rendu final du rapport de veille</p>
				</center>

                <h3>Envoi hebdomadaire</h3>
                <p>Le programme pourrait s'arr√™ter l√†, avec un rapport clair et standard issu des 7 derniers jours d'information. Cependant, l'id√©al serait d'avoir cette veille qui se r√©alise automatiquement chaque semaine pour ensuite envoyer le rapport sur sa boite mail avant 8h par exemple.</p>
                <p>Dans un premier temps, il convient de bien param√©trer son adresse mail et la configuration des param√®tres SMTP (Server et Port) afin d'officialiser le lien entre l'adresse mail et le programme. Pour certaines plateformes comme Gmail, il peut √™tre n√©cessaire de g√©n√©rer un token applicatif pour autoriser l'acc√®s. Tout ceci est assez simple √† l'aide du pacage <code>smtplib</code> de Python.</p>
                <p>Suite √† cela, il suffit simplement de d√©ployer ce programme sur un service Cloud comme GitHub, Databricks, AWS voire m√™me son propre NAS via une image Docker (c'est cette derni√®re option que j'ai personnellement choisie). Une fois d√©ploy√©, un petit cronjob pour lancer le programme chaque mardi √† 6h et le rapport arrive bien au chaud dans sa boite mail chaque semaine, faisant √©conomiser beaucoup de temps p√¥ur optimiser sa veille informative !</p>
                <p>En raison du nombre important d'√©tapes critiques, le programme enregistre chaque √©tape dans un fichier log pour retracer les √©v√®nements de mani√®re claire. De plus, toutes les donn√©es importantes sont stock√©es dans un fichier <code>.env</code> pour assurer une protection suppl√©mentaire.</p>
                <center>
                    <img src="../pages/images/rss_logger.png" alt="rss_log" width="100%">
                    <p class="caption">Exrtait du d√©but du logger</p>
				</center>

                <h3>Conclusion</h3>
                <p>Ce projet est un exemple typique d'automatisation d'une t√¢che r√©p√©titive √† l'aide d'outils appropri√©s, sans partir dans l'exc√®s de mod√®les disproportionn√©s et tout en gardant une souplesse et une personnalisation propre aux d√©sirs de chacun.</p>
                <p>Ce projet fait appel √† une logique de collecte, de nettoyage, de scraping de donn√©es, de formatage et de reporting automatis√©.</p>
            </article>
			<!-- /PageContent -->

		</div>
	</div>
</main>

<!-- Footer -->
<footer id="footer">
	<div class="container">
		<div class="row">
			<div class="col-md-3 widget">
				<h3 class="widget-title">Contact</h3>
				<div class="widget-body">
					<p><a href="mailto:#">langlais.alexandre03@gmail.com</a><br>
						Niort, France
					</p>	
				</div>
			</div>

			<div class="col-md-3 widget">
				<h3 class="widget-title">Mes r√©seaux</h3>
				<div class="widget-body">
					<p class="follow-me-icons">
						<a href="https://www.linkedin.com/in/alexlanglais/"><i class="fab fa-linkedin fa-2"></i></a>
						<a href="https://github.com/a-langlais"><i class="fab fa-github fa-2"></i></a>
					</p>
				</div>
			</div>

			<div class="col-md-6 widget">
				<h3 class="widget-title">A propos du site</h3>
				<div class="widget-body">
                    <p>Site web cod√© √† la sueur de mon front lors de froides soir√©es hivernales ‚ùÑÔ∏è</p>
					<p>Site web statique (HTML/CSS only), √† faible utilisation √©nergetique pour un impact environnemental minimal üå≥</p>
                    <p>Mod√®le de site web open-source, libre de copie et modification par quiconque le souhaite. Heberg√© et d√©ploy√© sur mon GitHub en public üòÅ</p>
				</div>
			</div>

		</div>
	</div>
</footer>

<footer id="underfooter">
	<div class="container">
		<div class="row">
			
			<div class="col-md-6 widget">
				<div class="widget-body">
					<p>Niort, France </p>
				</div>
			</div>

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p class="text-right">
						Copyright &copy; 2025, Alexandre LANGLAIS<br></p>
				</div>
			</div>

		</div>
	</div>
</footer>
<!-- /Footer -->

</body>
</html>
